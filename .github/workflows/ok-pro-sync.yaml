name: OK APK Sync from QuarkDrive (Enhanced)

concurrency: 
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  schedule:
    - cron: '0 */3 * * *'  # ÊØè3Â∞èÊó∂ËøêË°å‰∏ÄÊ¨°
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync:
    runs-on: ubuntu-latest
    steps:
    - name: Acquire Repository Lock üîí
      uses: softprops/turnstyle@v1
      with:
        same-branch-only: true
        poll-interval-seconds: 30
        abort-after-seconds: 1200
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0

    - name: Set up Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y jq curl unzip
        pip install requests pycryptodome pytz

    - name: Run Enhanced Quark Drive Sync
      env:
        QUARK_CK: ${{ secrets.QUARK_CK }}  # Â∞ÜÂ§∏ÂÖãckÂ≠òÂÖ•GitHub Secrets
        SHARE_URL: https://pan.quark.cn/s/6fead79bddaf
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        TARGET_REPO: ${{ github.repository }}
      run: |
        python - << "EOF"
        import os
        import json
        import re
        import time
        import requests
        from datetime import datetime
        from pathlib import Path
        import logging
        import hashlib
        import base64
        from Crypto.Cipher import AES
        import pytz
        
        # ÈÖçÁΩÆÊó•Âøó
        logging.basicConfig(level=logging.INFO, format='[%(asctime)s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
        log = logging.getLogger("quark_sync")
        
        # ÈÖçÁΩÆÂèÇÊï∞
        WORK_DIR = "temp_apks"
        APK_DIR = "apk"
        PRO_FOLDER = "OKÂàÜ‰∫´/OKÂΩ±ËßÜPro"
        STD_FOLDER = "OKÂàÜ‰∫´/OKÂΩ±ËßÜÊ†áÂáÜÁâà"
        
        # Á≤æÁ°ÆÁöÑË∑ØÂæÑÊ®°Êùø
        STD_PATH_TEMPLATES = {
            "leanback": STD_FOLDER + "/{version}/leanback-armeabi_v7a-{version_num}.apk",
            "mobile": STD_FOLDER + "/{version}/mobile-arm64_v8a-{version_num}.apk"
        }
        
        PRO_PATH_TEMPLATES = {
            "leanback": PRO_FOLDER + "/OKÂΩ±ËßÜProÔπ£ÁîµËßÜÁâàÔπ£--{version_num}.apk",
            "mobile": PRO_FOLDER + "/OKÂΩ±ËßÜProÔπ£ÊâãÊú∫ÁâàÔπ£--{version_num}.apk"
        }
        
        # ÁõÆÊ†áÈáçÂëΩÂêç
        RENAME_MAP = {
            "std_leanback": "leanback.apk",
            "std_mobile": "mobile.apk",
            "pro_leanback": "leanback-pro.apk",
            "pro_mobile": "mobile-pro.apk"
        }
        
        # Âåó‰∫¨Êó∂Âå∫
        TZ_BEIJING = pytz.timezone('Asia/Shanghai')
        
        def setup_git():
            try:
                actor = os.environ.get('GITHUB_ACTOR', 'github-actions')
                email = f"{actor}@users.noreply.github.com"
                
                subprocess.run(["git", "config", "user.name", actor], check=True)
                subprocess.run(["git", "config", "user.email", email], check=True)
                
                # ÊãâÂèñÊúÄÊñ∞Êõ¥ÊîπÈò≤Ê≠¢ÂÜ≤Á™Å
                subprocess.run(["git", "pull", "origin", "main", "--rebase"], check=True)
                
                log.info("GitÈÖçÁΩÆÂÆåÊàê")
                return True
            except Exception as e:
                log.error(f"GitËÆæÁΩÆÂ§±Ë¥•: {str(e)}")
                return False
        
        def commit_and_push(message):
            try:
                # Âè™Ê∑ªÂä†APKÁõÆÂΩïÂíåÁâàÊú¨Êñá‰ª∂
                subprocess.run(["git", "add", APK_DIR, "version.txt"], check=True)
                
                # Ê£ÄÊü•ÊòØÂê¶ÊúâÊõ¥Êîπ
                status = subprocess.run(["git", "status", "--porcelain"], capture_output=True, text=True)
                if not status.stdout.strip():
                    log.info("Ê≤°ÊúâÊõ¥ÊîπÈúÄË¶ÅÊèê‰∫§")
                    return True
                
                # Êèê‰∫§Êõ¥Êîπ
                subprocess.run(["git", "commit", "-m", message], check=True)
                
                token = os.environ['GITHUB_TOKEN']
                actor = os.environ.get('GITHUB_ACTOR', 'github-actions')
                repo = os.environ['TARGET_REPO']
                repo_url = f"https://{actor}:{token}@github.com/{repo}.git"
                
                # ÈáçËØïÊú∫Âà∂
                max_attempts = 3
                for attempt in range(1, max_attempts + 1):
                    try:
                        log.info(f"Â∞ùËØï {attempt}/{max_attempts}: Êé®ÈÄÅÊõ¥Êîπ...")
                        # Âú®Êé®ÈÄÅÂâçÂÜçÊ¨°ÊãâÂèñÊúÄÊñ∞Êõ¥Êîπ
                        subprocess.run(["git", "pull", "origin", "main", "--rebase"], check=True)
                        subprocess.run(["git", "push", repo_url, "HEAD:main"], check=True)
                        log.info("Êé®ÈÄÅÊàêÂäü")
                        return True
                    except Exception as e:
                        log.warning(f"Â∞ùËØï {attempt} Â§±Ë¥•: {str(e)}")
                        if attempt < max_attempts:
                            time.sleep(10)
                
                log.error(f"ÁªèËøá{max_attempts}Ê¨°Â∞ùËØïÂêé‰ªçÊó†Ê≥ïÊé®ÈÄÅÊõ¥Êîπ")
                return False
            except Exception as e:
                log.error(f"GitÊìç‰ΩúÂ§±Ë¥•: {str(e)}")
                return False
        
        def load_version_file():
            """ÂÆâÂÖ®Âä†ËΩΩÁâàÊú¨Êñá‰ª∂ÔºåÁ°Æ‰øù‰∏ç‰ºöÊ∏ÖÁ©∫"""
            version_path = Path("version.txt")
            versions = {}
            if version_path.exists():
                try:
                    with open(version_path, "r") as f:
                        versions = json.load(f)
                except Exception:
                    log.warning("ÁâàÊú¨Êñá‰ª∂Ê†ºÂºèÈîôËØØÔºå‰ΩÜ‰∏ç‰ºöÊ∏ÖÁ©∫")
            return versions
        
        def save_version_file(versions):
            version_path = Path("version.txt")
            with open(version_path, "w") as f:
                json.dump(versions, f, indent=2)
        
        def parse_cookies(cookie_str):
            cookies = {}
            for item in cookie_str.split(';'):
                item = item.strip()
                if not item:
                    continue
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies[key] = value
                else:
                    cookies[item] = None
            return cookies
        
        def decrypt_download_url(encrypted_url, file_key):
            """Ëß£ÂØÜÂ§∏ÂÖãÁΩëÁõò‰∏ãËΩΩURL"""
            # ÁîüÊàêAESÂØÜÈí•
            aes_key = hashlib.md5(file_key.encode()).hexdigest().encode()
            iv = b"ef0e50a8a48afdac"
            
            # Ëß£ÂØÜ
            cipher = AES.new(aes_key, AES.MODE_CBC, iv)
            encrypted_url = base64.b64decode(encrypted_url)
            decrypted = cipher.decrypt(encrypted_url)
            
            # ÁßªÈô§PKCS7Â°´ÂÖÖ
            pad = decrypted[-1]
            if pad < 16:
                decrypted = decrypted[:-pad]
            
            return decrypted.decode('utf-8')
        
        def get_all_share_files(share_url, cookies):
            """Ëé∑ÂèñÂàÜ‰∫´ÈìæÊé•‰∏ãÁöÑÊâÄÊúâÊñá‰ª∂"""
            share_id = share_url.split("/s/")[-1]
            api_url = "https://drive-pc.quark.cn/1/clouddrive/share/sharepage/detail"
            
            headers = {
                "Referer": share_url,
                "Content-Type": "application/json"
            }
            
            all_files = []
            page = 1
            has_more = True
            
            while has_more:
                payload = {
                    "share_id": share_id,
                    "pdir_fid": "",
                    "page": page,
                    "per_page": 50,
                    "file_type": 0
                }
                
                response = requests.post(api_url, json=payload, headers=headers, cookies=cookies)
                data = response.json()
                
                if data.get("data", {}).get("list"):
                    all_files.extend(data["data"]["list"])
                
                has_more = data.get("data", {}).get("is_more", 0) == 1
                page += 1
                time.sleep(0.5)
            
            return all_files
        
        def find_files_by_template(files, templates):
            """ÈÄöËøáÁ≤æÁ°ÆË∑ØÂæÑÊ®°ÊùøÊü•ÊâæÊñá‰ª∂"""
            found_files = {}
            
            for file in files:
                if not file.get("file_name") or not file.get("updated_at"):
                    continue
                
                path = file.get("path", "") + "/" + file["file_name"]
                
                # Â∞ùËØïÂåπÈÖçÊ†áÂáÜÁâàÊ®°Êùø
                for file_type, template in templates.items():
                    # ÊõøÊç¢ÁâàÊú¨Âç†‰ΩçÁ¨¶‰∏∫ÂåπÈÖçÈÄöÈÖçÁ¨¶
                    pattern = re.escape(template).replace(re.escape("{version}"), r"([\d.]+)") \
                                                .replace(re.escape("{version_num}"), r"([\d.]+)")
                    
                    match = re.match(pattern, path)
                    if match:
                        version = match.group(1)
                        # ÁâàÊú¨Âè∑‰∏≠ÁöÑÁÇπÈúÄË¶Å‰øùÁïô‰∏∫Â≠óÁ¨¶‰∏≤Áî®‰∫éÂåπÈÖç
                        version_num = match.group(2)
                        
                        if not version_num.replace(".", "").isdigit():
                            continue
                            
                        if file_type not in found_files or version > found_files[file_type]["version"]:
                            found_files[file_type] = {
                                "fid": file["fid"],
                                "key": file["hash_name"],
                                "version": version,
                                "version_num": version_num,
                                "path": path,
                                "size": file["size"],
                                "timestamp": int(file["updated_at"]),
                                "file_name": file["file_name"]
                            }
                        break
            
            return found_files
        
        def should_update(versions, file_type, new_version, new_date):
            """Âà§Êñ≠ÊòØÂê¶ÈúÄË¶ÅÊõ¥Êñ∞Ê≠§Êñá‰ª∂"""
            # Êñá‰ª∂Á±ªÂûãÂú®ÁâàÊú¨Êñá‰ª∂‰∏≠ÁöÑÈîÆÂêç
            key = RENAME_MAP[file_type]
            
            # Â¶ÇÊûúÁâàÊú¨Êñá‰ª∂‰∏≠‰∏çÂ≠òÂú®ËÆ∞ÂΩïÔºåÈúÄË¶ÅÊõ¥Êñ∞
            if key not in versions:
                log.info(f"Êñ∞Êñá‰ª∂: {key}")
                return True
            
            current_val = versions[key]
            if ',' not in current_val:
                log.info(f"ÁâàÊú¨Ê†ºÂºèÈîôËØØÔºåÈúÄË¶ÅÊõ¥Êñ∞: {key}")
                return True
            
            # Ëß£ÊûêÂΩìÂâçËÆ∞ÂΩïÁöÑÁâàÊú¨ÂíåÊó•Êúü
            current_ver, current_date = current_val.split(',', 1)
            
            # ÁâàÊú¨Âè∑ÊØîËæÉÔºà‰ΩøÁî®Êï∞Â≠óÂàÜÂâ≤ÊØîËæÉÔºâ
            def version_tuple(v):
                return tuple(map(int, v.split('.')))
            
            try:
                new_ver_tuple = version_tuple(new_version)
                current_ver_tuple = version_tuple(current_ver)
                
                # Êñ∞ÁâàÊú¨Âè∑Êõ¥È´ò
                if new_ver_tuple > current_ver_tuple:
                    log.info(f"Êñ∞ÁâàÊú¨: {current_ver} ‚Üí {new_version} ({key})")
                    return True
                
                # ÁâàÊú¨Áõ∏Âêå‰ΩÜÊó•ÊúüÊõ¥Êñ∞
                if new_ver_tuple == current_ver_tuple and new_date > current_date:
                    log.info(f"Áõ∏ÂêåÁâàÊú¨‰ΩÜÊñ∞ÊûÑÂª∫: {new_version} ({key})")
                    return True
                
                return False
            except ValueError:
                log.warning(f"ÁâàÊú¨Âè∑Ê†ºÂºèÊó†Ê≥ïËß£Êûê: {new_version} vs {current_ver}")
                # Â¶ÇÊûúÊó†Ê≥ïËß£ÊûêÁâàÊú¨Âè∑ÔºåÊåâÂ≠óÁ¨¶‰∏≤ÊØîËæÉ
                return new_version > current_ver or (new_version == current_ver and new_date > current_date)
        
        def download_file(cookies, file_info, save_path):
            """‰∏ãËΩΩÂçï‰∏™Êñá‰ª∂"""
            fid = file_info["fid"]
            file_name = file_info["file_name"]
            file_key = file_info["key"]
            
            # Ëé∑Âèñ‰∏ãËΩΩÈìæÊé•
            api_url = f"https://drive-pc.quark.cn/1/clouddrive/file/download?fid={fid}"
            headers = {
                "Referer": "https://pan.quark.cn/",
                "Origin": "https://pan.quark.cn"
            }
            
            response = requests.get(api_url, cookies=cookies, headers=headers, allow_redirects=False)
            
            if response.status_code == 302:
                encrypted_url = response.headers.get("Location", "")
            elif response.json().get("data"):
                encrypted_url = response.json().get("data")
            else:
                log.error(f"Êó†Ê≥ïËé∑Âèñ‰∏ãËΩΩURL: {file_name}")
                return False
            
            # Ëß£ÂØÜ‰∏ãËΩΩURL
            try:
                download_url = decrypt_download_url(encrypted_url, file_key)
            except Exception as e:
                log.error(f"Ëß£ÂØÜURLÂ§±Ë¥•: {file_name} - {str(e)}")
                return False
            
            # ÂàõÂª∫‰øùÂ≠òÁõÆÂΩï
            save_dir = os.path.dirname(save_path)
            if not os.path.exists(save_dir):
                os.makedirs(save_dir)
            
            # ‰∏ãËΩΩÊñá‰ª∂
            start_time = time.time()
            try:
                with requests.get(download_url, stream=True) as r:
                    r.raise_for_status()
                    with open(save_path, 'wb') as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
            except Exception as e:
                log.error(f"‰∏ãËΩΩÂ§±Ë¥•: {file_name} - {str(e)}")
                return False
            
            # È™åËØÅÊñá‰ª∂Â§ßÂ∞è
            downloaded_size = os.path.getsize(save_path)
            if downloaded_size != file_info["size"]:
                log.error(f"Êñá‰ª∂Â§ßÂ∞è‰∏çÂåπÈÖç: {file_name} ({downloaded_size} vs {file_info['size']})")
                os.remove(save_path)
                return False
            
            elapsed = time.time() - start_time
            size_mb = downloaded_size / (1024 * 1024)
            speed = size_mb / elapsed if elapsed > 0 else 0
            log.info(f"‰∏ãËΩΩÂÆåÊàê: {file_name} - {size_mb:.2f} MB, ËÄóÊó∂: {elapsed:.1f}s, ÈÄüÂ∫¶: {speed:.2f} MB/s")
            return True
        
        def main():
            log.info("="*50)
            log.info("ÂêØÂä®Â§∏ÂÖãÁΩëÁõòAPKÂêåÊ≠• (Â¢ûÂº∫Áâà)")
            log.info("="*50)
            
            # Ê£ÄÊü•ÁéØÂ¢ÉÂèòÈáè
            if not os.environ.get("QUARK_CK"):
                log.error("Áº∫Â∞ëQUARK_CKÁéØÂ¢ÉÂèòÈáè")
                return 1
            
            # ËÆæÁΩÆGit
            if not setup_git():
                return 2
            
            # ÂàõÂª∫‰∏¥Êó∂ÁõÆÂΩï
            os.makedirs(WORK_DIR, exist_ok=True)
            os.makedirs(APK_DIR, exist_ok=True)
            
            # Âä†ËΩΩÁâàÊú¨Êñá‰ª∂ (‰øùÊä§Áé∞ÊúâÂÜÖÂÆπ)
            current_versions = load_version_file()
            log.info("ÂΩìÂâçÁâàÊú¨Êñá‰ª∂ÂÜÖÂÆπ:\n" + json.dumps(current_versions, indent=2))
            
            # Ëß£ÊûêCookie
            cookies = parse_cookies(os.environ["QUARK_CK"])
            
            # Ëé∑ÂèñÊâÄÊúâÂàÜ‰∫´Êñá‰ª∂
            share_url = os.environ.get("SHARE_URL", "https://pan.quark.cn/s/6fead79bddaf")
            log.info(f"Ëé∑ÂèñÂàÜ‰∫´Êñá‰ª∂ÂàóË°®: {share_url}")
            files = get_all_share_files(share_url, cookies)
            
            if not files:
                log.error("Êó†Ê≥ïËé∑ÂèñÊñá‰ª∂ÂàóË°®ÊàñÂàóË°®‰∏∫Á©∫")
                return 3
            log.info(f"ÊâæÂà∞ {len(files)} ‰∏™Êñá‰ª∂")
            
            # Êü•ÊâæÊ†áÂáÜÁâàÊñá‰ª∂
            log.info("Êâ´ÊèèÊ†áÂáÜÁâàÊñá‰ª∂...")
            std_files = find_files_by_template(files, STD_PATH_TEMPLATES)
            if not std_files:
                log.error("Êú™ÊâæÂà∞Ê†áÂáÜÁâàÊñá‰ª∂")
            else:
                log.info(f"Ê†áÂáÜÁâàÂèëÁé∞: {len(std_files)} ‰∏™Êñá‰ª∂")
                for name, info in std_files.items():
                    log.info(f"  {name}: v{info['version']} (Êñá‰ª∂Âêç: {info['file_name']})")
            
            # Êü•Êâæ‰∏ì‰∏öÁâàÊñá‰ª∂
            log.info("Êâ´Êèè‰∏ì‰∏öÁâàÊñá‰ª∂...")
            pro_files = find_files_by_template(files, PRO_PATH_TEMPLATES)
            if not pro_files:
                log.error("Êú™ÊâæÂà∞‰∏ì‰∏öÁâàÊñá‰ª∂")
            else:
                log.info(f"‰∏ì‰∏öÁâàÂèëÁé∞: {len(pro_files)} ‰∏™Êñá‰ª∂")
                for name, info in pro_files.items():
                    log.info(f"  {name}: v{info['version_num']} (Êñá‰ª∂Âêç: {info['file_name']})")
            
            # Â§ÑÁêÜÊõ¥Êñ∞
            needs_update = False
            update_log = []
            
            # Â§ÑÁêÜÊ†áÂáÜÁâà
            if std_files:
                # ÂÅáËÆæÊ†áÂáÜÁâàÁöÑÊâÄÊúâÊñá‰ª∂ÂÖ±‰∫´Âêå‰∏ÄÁâàÊú¨Âè∑ÂíåÊó∂Èó¥Êà≥
                sample_file = next(iter(std_files.values()))
                
                # Ëé∑ÂèñÂåó‰∫¨Êó∂Èó¥
                dt = datetime.fromtimestamp(sample_file["timestamp"]/1000)
                dt_beijing = dt.astimezone(TZ_BEIJING)
                date_str = dt_beijing.strftime("%Y-%m-%d")
                
                log.info(f"Ê†áÂáÜÁâàÁâàÊú¨: {sample_file['version']}, ÂèëÂ∏ÉÊó∂Èó¥: {date_str}")
                
                for file_type, file_info in std_files.items():
                    key_name = f"std_{file_type}"
                    version_key = RENAME_MAP[key_name]
                    
                    if should_update(current_versions, key_name, file_info["version"], date_str):
                        # ‰∏ãËΩΩÊñá‰ª∂
                        temp_path = os.path.join(WORK_DIR, file_info["file_name"])
                        if download_file(cookies, file_info, temp_path):
                            # ÁßªÂä®Âπ∂ÈáçÂëΩÂêçÊñá‰ª∂
                            final_path = os.path.join(APK_DIR, RENAME_MAP[key_name])
                            os.rename(temp_path, final_path)
                            
                            # Êõ¥Êñ∞ÁâàÊú¨ËÆ∞ÂΩï
                            current_versions[version_key] = f"{file_info['version']},{date_str}"
                            update_log.append(f"{version_key} -> v{file_info['version']}")
                            needs_update = True
                        else:
                            log.error(f"‰∏ãËΩΩÂ§±Ë¥•: {version_key}")
            else:
                log.warning("Ë∑≥ËøáÊ†áÂáÜÁâàÔºåÊ≤°ÊúâÊâæÂà∞Êñá‰ª∂")
            
            # Â§ÑÁêÜ‰∏ì‰∏öÁâà
            if pro_files:
                # ÂÅáËÆæ‰∏ì‰∏öÁâàÁöÑÊâÄÊúâÊñá‰ª∂ÂÖ±‰∫´Âêå‰∏ÄÁâàÊú¨Âè∑ÂíåÊó∂Èó¥Êà≥
                sample_file = next(iter(pro_files.values()))
                
                # Ëé∑ÂèñÂåó‰∫¨Êó∂Èó¥
                dt = datetime.fromtimestamp(sample_file["timestamp"]/1000)
                dt_beijing = dt.astimezone(TZ_BEIJING)
                date_str = dt_beijing.strftime("%Y-%m-%d")
                
                log.info(f"‰∏ì‰∏öÁâàÁâàÊú¨: {sample_file['version_num']}, ÂèëÂ∏ÉÊó∂Èó¥: {date_str}")
                
                for file_type, file_info in pro_files.items():
                    key_name = f"pro_{file_type}"
                    version_key = RENAME_MAP[key_name]
                    
                    if should_update(current_versions, key_name, file_info["version_num"], date_str):
                        # ‰∏ãËΩΩÊñá‰ª∂
                        temp_path = os.path.join(WORK_DIR, file_info["file_name"])
                        if download_file(cookies, file_info, temp_path):
                            # ÁßªÂä®Âπ∂ÈáçÂëΩÂêçÊñá‰ª∂
                            final_path = os.path.join(APK_DIR, RENAME_MAP[key_name])
                            os.rename(temp_path, final_path)
                            
                            # Êõ¥Êñ∞ÁâàÊú¨ËÆ∞ÂΩï
                            current_versions[version_key] = f"{file_info['version_num']},{date_str}"
                            update_log.append(f"{version_key} -> v{file_info['version_num']}")
                            needs_update = True
                        else:
                            log.error(f"‰∏ãËΩΩÂ§±Ë¥•: {version_key}")
            else:
                log.warning("Ë∑≥Ëøá‰∏ì‰∏öÁâàÔºåÊ≤°ÊúâÊâæÂà∞Êñá‰ª∂")
            
            # Ê£ÄÊü•Âº∫Âà∂Êñá‰ª∂Â≠òÂú®
            if not needs_update:
                log.info("Ê≤°ÊúâÈúÄË¶ÅÊõ¥Êñ∞ÁöÑAPKÊñá‰ª∂")
                
                # Ê£ÄÊü•ÊòØÂê¶ÊâÄÊúâÊñá‰ª∂ÈÉΩÂ≠òÂú®
                for key in RENAME_MAP.values():
                    file_path = os.path.join(APK_DIR, key)
                    if not os.path.exists(file_path):
                        log.error(f"ÂÖ≥ÈîÆÊñá‰ª∂Áº∫Â§±: {key}")
                        return 4
            
            # ‰øùÂ≠òÁâàÊú¨Êñá‰ª∂
            if needs_update:
                log.info("Êõ¥Êñ∞ÁâàÊú¨Êñá‰ª∂")
                save_version_file(current_versions)
                
                # Êèê‰∫§Êõ¥Êîπ
                commit_msg = "Êõ¥Êñ∞APK: " + ", ".join(update_log)
                if commit_and_push(commit_msg):
                    log.info("ÂêåÊ≠•ÊàêÂäüÔºÅ")
                    return 0
                else:
                    log.error("Êèê‰∫§Â§±Ë¥•")
                    return 5
            else:
                log.info("ÊâÄÊúâÊñá‰ª∂Âùá‰∏∫ÊúÄÊñ∞ÁâàÊú¨")
                return 0
        
        if __name__ == "__main__":
            import subprocess
            import sys
            sys.exit(main())
        EOF

    - name: Release Repository Lock üîì
      if: always()
      uses: softprops/turnstyle@v1
      with:
        continue-on-error: true
        action: unlock
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Notify on failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const message = `üö® QuarkÁΩëÁõòAPKÂêåÊ≠•Â§±Ë¥•ÔºÅÂ∑•‰ΩúÊµÅËøêË°å: [${{ github.workflow }} #${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: message
          })

  cleanup:
    runs-on: ubuntu-latest
    needs: sync
    if: always()
    steps:
      - name: Clean up workspace
        run: |
          # Âà†Èô§‰∏¥Êó∂Â∑•‰ΩúÁõÆÂΩï
          rm -rf temp_apks
          
          # Ê∏ÖÈô§Êú™Ë∑üË∏™ÁöÑÊñá‰ª∂
          git clean -f -d
