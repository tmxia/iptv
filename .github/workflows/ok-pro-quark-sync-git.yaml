name: QuarkDrive APK Sync

concurrency: 
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  schedule:
    - cron: '0 */3 * * *'  # æ¯3å°æ—¶è¿è¡Œä¸€æ¬¡
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync:
    runs-on: ubuntu-latest
    steps:
    - name: Acquire Repository Lock
      uses: softprops/turnstyle@v1
      with:
        same-branch-only: true
        poll-interval-seconds: 30
        abort-after-seconds: 1200
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y build-essential libssl-dev
        pip install requests pycryptodome pytz

    - name: Run Quark Sync
      env:
        QUARK_CK: ${{ secrets.QUARK_CK }}
        SHARE_URL: https://pan.quark.cn/s/6fead79bddaf
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      run: |
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        mkdir -p apk temp_apks
        
        # å¦‚æœç‰ˆæœ¬æ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»º
        if [ ! -f version.txt ]; then
          echo '{}' > version.txt
        fi
        
        # æ‰§è¡ŒPythonè„šæœ¬
        python - << "EOF"
        import os
        import json
        import re
        import time
        import requests
        import logging
        import hashlib
        import base64
        from Crypto.Cipher import AES
        from pathlib import Path
        from datetime import datetime
        import pytz
        import subprocess
        import sys
        
        # --- é…ç½®å’Œå¸¸é‡ ---
        WORK_DIR = "temp_apks"
        APK_DIR = "apk"
        TZ_BEIJING = pytz.timezone('Asia/Shanghai')
        
        # è·¯å¾„æ¨¡æ¿ - ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
        PATH_TEMPLATES = {
            "std": {
                "leanback": r"OKåˆ†äº«/OKå½±è§†æ ‡å‡†ç‰ˆ/(?P<version>[\d.]+)/leanback-armeabi_v7a-(?P<version_num>[\d.]+)\.apk",
                "mobile": r"OKåˆ†äº«/OKå½±è§†æ ‡å‡†ç‰ˆ/(?P<version>[\d.]+)/mobile-arm64_v8a-(?P<version_num>[\d.]+)\.apk"
            },
            "pro": {
                "leanback": r"OKåˆ†äº«/OKå½±è§†Pro/OKå½±è§†Proï¹£ç”µè§†ç‰ˆï¹£--(?P<version_num>[\d.]+)\.apk",
                "mobile": r"OKåˆ†äº«/OKå½±è§†Pro/OKå½±è§†Proï¹£æ‰‹æœºç‰ˆï¹£--(?P<version_num>[\d.]+)\.apk"
            }
        }
        
        # ç›®æ ‡é‡å‘½åæ˜ å°„
        RENAME_MAP = {
            "std_leanback": "leanback.apk",
            "std_mobile": "mobile.apk",
            "pro_leanback": "leanback-pro.apk",
            "pro_mobile": "mobile-pro.apk"
        }
        
        # --- æ—¥å¿—é…ç½® ---
        def setup_logger():
            logger = logging.getLogger("quark_sync")
            logger.setLevel(logging.DEBUG)
            
            # æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setLevel(logging.INFO)
            console_formatter = logging.Formatter('[%(levelname)-8s] %(message)s')
            console_handler.setFormatter(console_formatter)
            
            # æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler("quark_sync.log")
            file_handler.setLevel(logging.DEBUG)
            file_formatter = logging.Formatter('[%(asctime)s][%(levelname)-8s] %(message)s', datefmt='%Y-%m-%d %H:%M:%S')
            file_handler.setFormatter(file_formatter)
            
            logger.addHandler(console_handler)
            logger.addHandler(file_handler)
            
            return logger
        
        log = setup_logger()
        
        # --- æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ---
        def parse_cookies(cookie_str):
            """è§£æCookieå­—ç¬¦ä¸²ä¸ºå­—å…¸"""
            cookies = {}
            for item in cookie_str.split(';'):
                item = item.strip()
                if not item:
                    continue
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies[key.strip()] = value.strip()
            return cookies
        
        def get_safe_cookie_log(cookies):
            """å®‰å…¨è®°å½•Cookiesï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
            safe_keys = []
            sensitive_keys = ['__sdid', 'isg', 'tfstk', 'cookie', 'token', 'key', 'secret']
            
            for key in cookies.keys():
                if any(sk in key.lower() for sk in sensitive_keys):
                    safe_keys.append(f"{key}=***")
                else:
                    safe_keys.append(f"{key}")
            
            return ', '.join(safe_keys)
        
        def decrypt_download_url(encrypted_url, file_key):
            """è§£å¯†å¤¸å…‹ç½‘ç›˜ä¸‹è½½URL"""
            try:
                # ç”ŸæˆAESå¯†é’¥
                aes_key = hashlib.md5(file_key.encode()).hexdigest().encode()
                iv = b"ef0e50a8a48afdac"
                
                # è§£ç base64
                encrypted_data = base64.b64decode(encrypted_url)
                
                # åˆ›å»ºè§£å¯†å™¨
                cipher = AES.new(aes_key, AES.MODE_CBC, iv)
                decrypted = cipher.decrypt(encrypted_data)
                
                # ç§»é™¤PKCS7å¡«å……
                pad = decrypted[-1]
                if 1 <= pad <= 16:
                    decrypted = decrypted[:-pad]
                
                return decrypted.decode('utf-8')
            except Exception as e:
                log.error(f"ä¸‹è½½URLè§£å¯†å¤±è´¥: {str(e)}")
                return None
        
        def get_share_files(share_url, cookies):
            """è·å–åˆ†äº«é“¾æ¥ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ - ä½¿ç”¨GETæ–¹æ³•è§£å†³405é”™è¯¯"""
            log.info(f"è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨: {share_url}")
            
            # æå–åˆ†äº«ID
            match = re.search(r'pan\.quark\.cn/s/([a-zA-Z0-9]+)', share_url)
            if match:
                share_id = match.group(1)
            else:
                log.error(f"æ— æ³•æå–åˆ†äº«ID: {share_url}")
                return None
            
            # ä½¿ç”¨GETè¯·æ±‚å’ŒæŸ¥è¯¢å‚æ•° - è§£å†³405é”™è¯¯
            api_url = "https://drive-pc.quark.cn/1/clouddrive/share/sharepage/detail"
            headers = {
                "Referer": share_url,
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
                "Origin": "https://pan.quark.cn",
                "Accept": "application/json, text/plain, */*"
            }
            
            all_files = []
            page = 1
            has_more = True
            
            while has_more:
                # ä½¿ç”¨æŸ¥è¯¢å‚æ•°è€Œä¸æ˜¯JSONä½“
                params = {
                    "share_id": share_id,
                    "pdir_fid": "0",
                    "page": page,
                    "per_page": 100,
                    "file_type": 0,
                    "stoken": cookies.get("__kp", ""),
                    "pwd_id": ""
                }
                
                try:
                    response = requests.get(
                        api_url,
                        params=params,
                        headers=headers,
                        cookies=cookies,
                        timeout=60  # å¢åŠ è¶…æ—¶æ—¶é—´
                    )
                    
                    if response.status_code != 200:
                        log.error(f"APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                        log.error(f"è¯·æ±‚URL: {response.url}")
                        log.error(f"å“åº”å†…å®¹: {response.text[:500]}")
                        return None
                    
                    data = response.json()
                    
                    # æ£€æŸ¥APIé”™è¯¯ç 
                    if data.get("status", {}).get("code") not in (200, None):
                        log.error(f"APIé”™è¯¯: {data.get('status', {}).get('message')}")
                        return None
                    
                    # æå–æ–‡ä»¶åˆ—è¡¨
                    files_list = data.get("data", {}).get("list", [])
                    all_files.extend(files_list)
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
                    has_more = data.get("data", {}).get("is_more", 0) == 1
                    page += 1
                    
                    # é¿å…é¢‘ç¹è¯·æ±‚
                    time.sleep(1)  # ç¨å¾®å¢åŠ ç­‰å¾…æ—¶é—´
                    
                except requests.exceptions.Timeout:
                    log.error("APIè¯·æ±‚è¶…æ—¶ï¼Œå°†é‡è¯•")
                    return None
                except Exception as e:
                    log.error(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}")
                    return None
            
            log.info(f"è·å–åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
            return all_files
        
        def match_file_path(path, pattern):
            """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ–‡ä»¶è·¯å¾„"""
            match = re.search(pattern, path)
            if match:
                return match.groupdict()
            return None
        
        def compare_versions(v1, v2):
            """å¥å£®çš„ç‰ˆæœ¬å·æ¯”è¾ƒ"""
            def parse_version(v):
                parts = []
                for part in v.split('.'):
                    try:
                        parts.append(int(part))
                    except ValueError:
                        # å¤„ç†éæ•°å­—éƒ¨åˆ†
                        parts.append(part)
                return tuple(parts)
            
            try:
                return parse_version(v2) > parse_version(v1)
            except Exception:
                # å›é€€åˆ°å­—ç¬¦ä¸²æ¯”è¾ƒ
                return v2 > v1
        
        def should_update(current_versions, file_key, new_version, new_date):
            """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°"""
            if file_key not in current_versions:
                return True
            
            current_val = current_versions[file_key]
            if ',' not in current_val:
                return True
            
            try:
                current_ver, current_date = current_val.split(',', 1)
            except ValueError:
                return True
            
            # ç‰ˆæœ¬å·æ¯”è¾ƒ
            version_newer = compare_versions(current_ver, new_version)
            
            # ç›¸åŒç‰ˆæœ¬ä½†æ—¥æœŸæ›´æ–°
            same_version_newer = (current_ver == new_version) and (new_date > current_date)
            
            return version_newer or same_version_newer
        
        def download_file(download_url, save_path):
            """ä¸‹è½½æ–‡ä»¶å¸¦é‡è¯•æœºåˆ¶"""
            max_retries = 3
            for attempt in range(1, max_retries + 1):
                try:
                    log.info(f"ä¸‹è½½å°è¯• {attempt}/{max_retries}: {save_path}")
                    with requests.get(download_url, stream=True, timeout=120) as r:  # å¢åŠ è¶…æ—¶æ—¶é—´
                        r.raise_for_status()
                        
                        # è·å–æ–‡ä»¶å¤§å°
                        file_size = int(r.headers.get('content-length', 0))
                        log.info(f"æ–‡ä»¶å¤§å°: {file_size/(1024*1024):.2f} MB")
                        
                        with open(save_path, 'wb') as f:
                            downloaded = 0
                            start_time = time.time()
                            
                            for chunk in r.iter_content(chunk_size=8192):
                                if chunk:
                                    f.write(chunk)
                                    downloaded += len(chunk)
                                    
                                    # æ¯ç§’æ›´æ–°ä¸€æ¬¡è¿›åº¦
                                    if time.time() - start_time > 1:
                                        percent = (downloaded / file_size * 100) if file_size > 0 else 0
                                        elapsed = time.time() - start_time
                                        speed = downloaded / (elapsed * 1024)  # KB/s
                                        log.info(f"è¿›åº¦: {percent:.1f}% | é€Ÿåº¦: {speed:.1f} KB/s")
                                        start_time = time.time()
                    
                    # éªŒè¯æ–‡ä»¶å¤§å°
                    if file_size > 0 and os.path.getsize(save_path) != file_size:
                        log.warning("æ–‡ä»¶å¤§å°ä¸åŒ¹é…ï¼Œé‡è¯•...")
                        os.remove(save_path)
                        continue
                        
                    return True
                except Exception as e:
                    log.warning(f"ä¸‹è½½å¤±è´¥: {str(e)}")
                    if os.path.exists(save_path):
                        os.remove(save_path)
            
            return False
        
        def get_download_url(fid, cookies):
            """è·å–æ–‡ä»¶ä¸‹è½½URL"""
            api_url = f"https://drive-pc.quark.cn/1/clouddrive/file/download?fid={fid}"
            headers = {
                "Referer": "https://pan.quark.cn/",
                "Origin": "https://pan.quark.cn",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
            }
            
            try:
                response = requests.get(
                    api_url, 
                    cookies=cookies, 
                    headers=headers, 
                    allow_redirects=False,
                    timeout=30
                )
                
                if response.status_code == 302:
                    return response.headers.get("Location", "")
                elif response.status_code == 200:
                    data = response.json()
                    return data.get("data", "")
                else:
                    log.error(f"æ— æ³•è·å–ä¸‹è½½URL: HTTP {response.status_code}")
                    log.error(f"å“åº”å†…å®¹: {response.text[:500]}")
                    return None
            except Exception as e:
                log.error(f"è·å–ä¸‹è½½URLå¤±è´¥: {str(e)}")
                return None
        
        def setup_git():
            """é…ç½®Gitç¯å¢ƒ"""
            try:
                actor = os.environ.get('GITHUB_ACTOR', 'github-actions')
                email = f"{actor}@users.noreply.github.com"
                
                subprocess.run(["git", "config", "user.name", actor], check=True)
                subprocess.run(["git", "config", "user.email", email], check=True)
                
                # æ‹‰å–æœ€æ–°æ›´æ”¹é˜²æ­¢å†²çª
                subprocess.run(["git", "pull", "origin", "main", "--rebase"], check=True)
                
                return True
            except Exception as e:
                log.error(f"Gité…ç½®å¤±è´¥: {str(e)}")
                return False
        
        def commit_and_push(message):
            """æäº¤å¹¶æ¨é€æ›´æ”¹"""
            try:
                # æ·»åŠ APKç›®å½•å’Œç‰ˆæœ¬æ–‡ä»¶
                subprocess.run(["git", "add", APK_DIR, "version.txt"], check=True)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ”¹
                status = subprocess.run(
                    ["git", "status", "--porcelain"], 
                    capture_output=True, 
                    text=True,
                    check=True
                )
                
                if not status.stdout.strip():
                    log.info("æ²¡æœ‰æ›´æ”¹éœ€è¦æäº¤")
                    return True
                
                # æäº¤æ›´æ”¹
                subprocess.run(["git", "commit", "-m", message], check=True)
                
                token = os.environ['GITHUB_TOKEN']
                actor = os.environ.get('GITHUB_ACTOR', 'github-actions')
                repo_url = f"https://{actor}:{token}@github.com/{os.environ['GITHUB_REPOSITORY']}.git"
                
                # é‡è¯•æœºåˆ¶
                max_attempts = 3
                for attempt in range(1, max_attempts + 1):
                    try:
                        subprocess.run(["git", "pull", "origin", "main", "--rebase"], check=True)
                        subprocess.run(["git", "push", repo_url, "HEAD:main"], check=True)
                        log.info("æ¨é€æˆåŠŸ")
                        return True
                    except subprocess.CalledProcessError as e:
                        log.warning(f"Gitæ“ä½œå¤±è´¥: {str(e)}")
                        if attempt < max_attempts:
                            time.sleep(10)
                            subprocess.run(["git", "reset", "--hard", "HEAD"], check=True)
                
                log.error(f"ç»è¿‡{max_attempts}æ¬¡å°è¯•åä»æ— æ³•æ¨é€æ›´æ”¹")
                return False
            except Exception as e:
                log.error(f"Gitæäº¤å¤±è´¥: {str(e)}")
                return False
        
        def load_version_file():
            """åŠ è½½ç‰ˆæœ¬æ–‡ä»¶"""
            version_path = Path("version.txt")
            versions = {}
            if version_path.exists():
                try:
                    with open(version_path, "r") as f:
                        versions = json.load(f)
                except:
                    log.warning("ç‰ˆæœ¬æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œä½†ä¸ä¼šæ¸…ç©º")
            return versions
        
        def save_version_file(versions):
            """ä¿å­˜ç‰ˆæœ¬æ–‡ä»¶"""
            with open("version.txt", "w") as f:
                json.dump(versions, f, indent=2)
        
        def main():
            log.info("=" * 70)
            log.info("ğŸš€ å¯åŠ¨å¤¸å…‹ç½‘ç›˜APKåŒæ­¥")
            log.info("=" * 70)
            
            # æ£€æŸ¥å¿…è¦ç¯å¢ƒå˜é‡
            if not os.environ.get("QUARK_CK"):
                log.critical("âŒ ç¼ºå°‘QUARK_CKç¯å¢ƒå˜é‡")
                return 1
            
            # è®¾ç½®Git
            if not setup_git():
                log.critical("âŒ Gitè®¾ç½®å¤±è´¥")
                return 2
            
            # åˆ›å»ºç›®å½•
            os.makedirs(WORK_DIR, exist_ok=True)
            os.makedirs(APK_DIR, exist_ok=True)
            
            # åŠ è½½ç‰ˆæœ¬æ–‡ä»¶
            current_versions = load_version_file()
            
            # è§£æCookies
            quark_ck = os.environ["QUARK_CK"]
            cookies = parse_cookies(quark_ck)
            log.debug(f"ä½¿ç”¨Cookies: {get_safe_cookie_log(cookies)}")
            
            # è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨
            share_url = os.environ.get("SHARE_URL", "https://pan.quark.cn/s/6fead79bddaf")
            
            # å¢å¼ºé‡è¯•æœºåˆ¶
            max_attempts = 5
            files = None
            for attempt in range(1, max_attempts + 1):
                log.info(f"å°è¯•è·å–æ–‡ä»¶åˆ—è¡¨ (å°è¯• {attempt}/{max_attempts})")
                files = get_share_files(share_url, cookies)
                if files is not None:
                    break
                
                log.warning(f"è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥ï¼Œç­‰å¾… {10 * attempt} ç§’åé‡è¯•...")
                time.sleep(10 * attempt)  # æŒ‡æ•°é€€é¿
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œæ£€æŸ¥Cookieæœ‰æ•ˆæ€§
                if attempt == max_attempts:
                    log.error("å¤šæ¬¡å°è¯•åä»æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨")
                    # æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆ
                    if "__kp" not in cookies:
                        log.error("âŒ Cookieä¸­ç¼ºå°‘å…³é”®å­—æ®µ __kp")
                    if "__sdid" not in cookies:
                        log.error("âŒ Cookieä¸­ç¼ºå°‘å…³é”®å­—æ®µ __sdid")
                    if "b-user-id" not in cookies:
                        log.error("âŒ Cookieä¸­ç¼ºå°‘å…³é”®å­—æ®µ b-user-id")
            
            if not files:
                log.error("âŒ æ— æ³•è·å–æ–‡ä»¶åˆ—è¡¨ï¼Œç»ˆæ­¢åŒæ­¥")
                return 3
            
            # åŒ¹é…ç›®æ ‡æ–‡ä»¶
            matched_files = {}
            for file in files:
                file_path = f"{file.get('path', '')}/{file['file_name']}"
                
                # å°è¯•åŒ¹é…æ ‡å‡†ç‰ˆ
                for file_type, pattern in PATH_TEMPLATES["std"].items():
                    match = match_file_path(file_path, pattern)
                    if match:
                        key = f"std_{file_type}"
                        file_info = {
                            **file,
                            **match,
                            "type": key
                        }
                        # åªä¿ç•™æœ€æ–°ç‰ˆæœ¬
                        if key not in matched_files or compare_versions(
                            matched_files[key].get("version_num", "0"), 
                            file_info.get("version_num", "0")
                        ):
                            matched_files[key] = file_info
                
                # å°è¯•åŒ¹é…ä¸“ä¸šç‰ˆ
                for file_type, pattern in PATH_TEMPLATES["pro"].items():
                    match = match_file_path(file_path, pattern)
                    if match:
                        key = f"pro_{file_type}"
                        file_info = {
                            **file,
                            **match,
                            "type": key
                        }
                        if key not in matched_files or compare_versions(
                            matched_files[key].get("version_num", "0"), 
                            file_info.get("version_num", "0")
                        ):
                            matched_files[key] = file_info
            
            # å¤„ç†æ›´æ–°
            needs_update = False
            update_log = []
            
            for key, file_info in matched_files.items():
                file_key = RENAME_MAP.get(key)
                if not file_key:
                    log.warning(f"è·³è¿‡æ— æ•ˆæ–‡ä»¶ç±»å‹: {key}")
                    continue
                
                # è·å–æ–‡ä»¶æ—¥æœŸ
                timestamp = file_info.get("updated_at", 0) / 1000
                file_date = datetime.fromtimestamp(timestamp).strftime("%Y-%m-%d")
                
                version_num = file_info.get("version_num") or file_info.get("version", "0.0.0")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°
                if should_update(current_versions, file_key, version_num, file_date):
                    # è·å–ä¸‹è½½URL
                    download_url_enc = get_download_url(file_info["fid"], cookies)
                    if not download_url_enc:
                        log.error(f"æ— æ³•è·å–ä¸‹è½½URL: {file_info['file_name']}")
                        continue
                    
                    # è§£å¯†URL
                    download_url = decrypt_download_url(download_url_enc, file_info["hash_name"])
                    if not download_url:
                        log.error(f"ä¸‹è½½URLè§£å¯†å¤±è´¥: {file_info['file_name']}")
                        continue
                    
                    # ä¸‹è½½æ–‡ä»¶
                    temp_path = os.path.join(WORK_DIR, file_info["file_name"])
                    if download_file(download_url, temp_path):
                        # ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
                        dest_path = os.path.join(APK_DIR, file_key)
                        if os.path.exists(dest_path):
                            os.remove(dest_path)
                        os.rename(temp_path, dest_path)
                        
                        # æ›´æ–°ç‰ˆæœ¬è®°å½•
                        current_versions[file_key] = f"{version_num},{file_date}"
                        update_log.append(f"{file_key} (v{version_num})")
                        needs_update = True
                        log.info(f"âœ… æˆåŠŸæ›´æ–°: {file_key}")
                    else:
                        log.error(f"âŒ ä¸‹è½½å¤±è´¥: {file_info['file_name']}")
                else:
                    log.info(f"â†ªï¸ è·³è¿‡: {file_key} (å·²æ˜¯æœ€æ–°)")
            
            # ä¿å­˜æ›´æ–°
            if needs_update:
                save_version_file(current_versions)
                commit_msg = "æ›´æ–°APK: " + ", ".join(update_log)
                if commit_and_push(commit_msg):
                    log.info("âœ… åŒæ­¥å®Œæˆå¹¶æäº¤åˆ°ä»“åº“")
                else:
                    log.error("âŒ æäº¤åˆ°ä»“åº“å¤±è´¥")
                    return 4
            else:
                log.info("âœ… æ‰€æœ‰æ–‡ä»¶å‡ä¸ºæœ€æ–°ç‰ˆæœ¬")
            
            return 0
        
        if __name__ == "__main__":
            try:
                exit_code = main()
                log.info("=" * 70)
                log.info(f"ğŸ å·¥ä½œæµç»“æŸ (ä»£ç : {exit_code})")
                sys.exit(exit_code)
            except Exception as e:
                import traceback
                log.error(f"âŒ æœªæ•è·çš„å¼‚å¸¸: {str(e)}")
                log.error(traceback.format_exc())
                sys.exit(99)
        EOF

    - name: Archive logs
      if: always()
      run: |
        timestamp=$(date +%Y%m%d_%H%M%S)
        gzip quark_sync.log
        mv quark_sync.log.gz "quark_sync_${timestamp}.log.gz"
        
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: sync-logs
        path: quark_sync_*.log.gz

    - name: Release Repository Lock
      if: always()
      uses: softprops/turnstyle@v1
      with:
        continue-on-error: true
        action: unlock
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

  cleanup:
    runs-on: ubuntu-latest
    needs: sync
    if: always()
    steps:
      - name: Clean workspace
        run: |
          rm -rf temp_apks
          git clean -f -d
          
      - name: Verify APK files
        run: |
          # æ£€æŸ¥APKç›®å½•ä¸‹æ˜¯å¦æœ‰æ–‡ä»¶
          if [ -z "$(ls -A apk/)" ]; then
            echo "âŒ APKç›®å½•ä¸ºç©ºï¼ŒåŒæ­¥å¯èƒ½å¤±è´¥"
            exit 1
          fi
          echo "âœ… APKæ–‡ä»¶éªŒè¯é€šè¿‡"

      - name: Notify status
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            const status = '${{ job.status }}';
            const runId = '${{ github.run_id }}';
            const repo = '${{ github.repository }}';
            const workflow = '${{ github.workflow }}';
            const runNumber = '${{ github.run_number }}';
            
            const message = status === 'success' 
              ? `âœ… å¤¸å…‹ç½‘ç›˜åŒæ­¥æˆåŠŸï¼å·¥ä½œæµè¿è¡Œ: [${workflow} #${runNumber}](https://github.com/${repo}/actions/runs/${runId})`
              : `âŒ å¤¸å…‹ç½‘ç›˜åŒæ­¥å¤±è´¥ï¼å·¥ä½œæµè¿è¡Œ: [${workflow} #${runNumber}](https://github.com/${repo}/actions/runs/${runId})`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: message
            });