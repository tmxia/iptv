name: OK APK Sync from QuarkDrive

concurrency: 
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

on:
  schedule:
    - cron: '0 */3 * * *'  # æ¯3å°æ—¶è¿è¡Œä¸€æ¬¡
  workflow_dispatch:

permissions:
  contents: write

jobs:
  sync:
    runs-on: ubuntu-latest
    steps:
    - name: Acquire Repository Lock ğŸ”’
      uses: softprops/turnstyle@v1
      with:
        same-branch-only: true
        poll-interval-seconds: 30
        abort-after-seconds: 1200
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        fetch-depth: 0
        
    - name: Setup Python
      uses: actions/setup-python@v5
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y \
          build-essential \
          libssl-dev \
          python3-dev \
          python3-pip \
          libffi-dev
        pip install requests pycryptodome pytz

    - name: Run Quark Drive Sync with Enhanced Logging
      env:
        QUARK_CK: ${{ secrets.QUARK_CK }}
        SHARE_URL: https://pan.quark.cn/s/6fead79bddaf
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        TARGET_REPO: ${{ github.repository }}
      run: |
        python - << "EOF"
        import os
        import json
        import re
        import time
        import requests
        from datetime import datetime
        from pathlib import Path
        import logging
        import hashlib
        import base64
        from Crypto.Cipher import AES
        import pytz
        import subprocess
        import sys
        
        # é…ç½®è¯¦ç»†çš„æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,
            format='[%(asctime)s][%(levelname)-8s] %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        log = logging.getLogger("quark_sync")
        log.setLevel(logging.DEBUG)  # å¯ç”¨è¯¦ç»†è°ƒè¯•æ—¥å¿—
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        file_handler = logging.FileHandler("quark_sync.log")
        file_handler.setFormatter(logging.Formatter('[%(asctime)s][%(levelname)-8s] %(message)s'))
        log.addHandler(file_handler)
        
        # é…ç½®å‚æ•°
        WORK_DIR = "temp_apks"
        APK_DIR = "apk"
        PRO_FOLDER = "OKåˆ†äº«/OKå½±è§†Pro"
        STD_FOLDER = "OKåˆ†äº«/OKå½±è§†æ ‡å‡†ç‰ˆ"
        
        # ç²¾ç¡®çš„è·¯å¾„æ¨¡æ¿
        STD_PATH_TEMPLATES = {
            "leanback": STD_FOLDER + "/{version}/leanback-armeabi_v7a-{version_num}.apk",
            "mobile": STD_FOLDER + "/{version}/mobile-arm64_v8a-{version_num}.apk"
        }
        
        PRO_PATH_TEMPLATES = {
            "leanback": PRO_FOLDER + "/OKå½±è§†Proï¹£ç”µè§†ç‰ˆï¹£--{version_num}.apk",
            "mobile": PRO_FOLDER + "/OKå½±è§†Proï¹£æ‰‹æœºç‰ˆï¹£--{version_num}.apk"
        }
        
        # ç›®æ ‡é‡å‘½å
        RENAME_MAP = {
            "std_leanback": "leanback.apk",
            "std_mobile": "mobile.apk",
            "pro_leanback": "leanback-pro.apk",
            "pro_mobile": "mobile-pro.apk"
        }
        
        # åŒ—äº¬æ—¶åŒº
        TZ_BEIJING = pytz.timezone('Asia/Shanghai')
        
        def setup_git():
            try:
                log.info(">>> é…ç½®Gitç¯å¢ƒ")
                actor = os.environ.get('GITHUB_ACTOR', 'github-actions')
                email = f"{actor}@users.noreply.github.com"
                
                subprocess.run(["git", "config", "user.name", actor], check=True)
                subprocess.run(["git", "config", "user.email", email], check=True)
                
                # æ‹‰å–æœ€æ–°æ›´æ”¹é˜²æ­¢å†²çª
                subprocess.run(["git", "pull", "origin", "main", "--rebase"], check=True)
                
                log.info("Gité…ç½®å®Œæˆ")
                return True
            except subprocess.CalledProcessError as e:
                log.error(f"Gitå‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}")
                log.error(f"å‘½ä»¤è¾“å‡º: {e.output if e.output else 'æ— '}")
                return False
            except Exception as e:
                log.error(f"Gitè®¾ç½®å¤±è´¥: {str(e)}")
                return False
        
        def commit_and_push(message):
            try:
                log.info(f">>> å‡†å¤‡æäº¤æ›´æ–°: {message}")
                
                # åªæ·»åŠ APKç›®å½•å’Œç‰ˆæœ¬æ–‡ä»¶
                subprocess.run(["git", "add", APK_DIR, "version.txt"], check=True)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ”¹
                status = subprocess.run(
                    ["git", "status", "--porcelain"], 
                    capture_output=True, 
                    text=True,
                    check=True
                )
                
                if not status.stdout.strip():
                    log.info("æ²¡æœ‰æ›´æ”¹éœ€è¦æäº¤")
                    return True
                
                # æäº¤æ›´æ”¹
                subprocess.run(["git", "commit", "-m", message], check=True)
                
                token = os.environ['GITHUB_TOKEN']
                actor = os.environ.get('GITHUB_ACTOR', 'github-actions')
                repo = os.environ['TARGET_REPO']
                repo_url = f"https://{actor}:{token}@github.com/{repo}.git"
                
                # é‡è¯•æœºåˆ¶
                max_attempts = 3
                for attempt in range(1, max_attempts + 1):
                    try:
                        log.info(f"å°è¯• {attempt}/{max_attempts}: æ‹‰å–è¿œç¨‹æœ€æ–°æ›´æ”¹å¹¶å˜åŸº...")
                        subprocess.run(["git", "pull", "origin", "main", "--rebase"], check=True)
                        
                        log.info(f"å°è¯• {attempt}/{max_attempts}: æ¨é€æ›´æ”¹...")
                        subprocess.run(["git", "push", repo_url, "HEAD:main"], check=True)
                        log.info("æ¨é€æˆåŠŸ")
                        return True
                    except subprocess.CalledProcessError as e:
                        log.warning(f"Gitæ“ä½œå¤±è´¥: {str(e)}")
                        log.warning(f"å‘½ä»¤è¾“å‡º: {e.output if e.output else 'æ— '}")
                        if attempt < max_attempts:
                            time.sleep(10)
                            log.info("é‡è¯•å‰æ¢å¤GitçŠ¶æ€...")
                            subprocess.run(["git", "reset", "--hard", "HEAD"], check=True)
                    except Exception as e:
                        log.warning(f"å°è¯• {attempt} å¤±è´¥: {str(e)}")
                        if attempt < max_attempts:
                            time.sleep(10)
                
                log.error(f"ç»è¿‡{max_attempts}æ¬¡å°è¯•åä»æ— æ³•æ¨é€æ›´æ”¹")
                return False
            except Exception as e:
                log.error(f"Gitæäº¤å¤±è´¥: {str(e)}")
                return False
        
        def load_version_file():
            """å®‰å…¨åŠ è½½ç‰ˆæœ¬æ–‡ä»¶ï¼Œç¡®ä¿ä¸ä¼šæ¸…ç©º"""
            version_path = Path("version.txt")
            versions = {}
            if version_path.exists():
                try:
                    with open(version_path, "r") as f:
                        log.info(f"åŠ è½½ç°æœ‰ç‰ˆæœ¬æ–‡ä»¶: {version_path}")
                        versions = json.load(f)
                        log.debug(f"ç‰ˆæœ¬æ–‡ä»¶å†…å®¹:\n{json.dumps(versions, indent=2)}")
                except json.JSONDecodeError:
                    log.warning("ç‰ˆæœ¬æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼ˆJSONè§£æå¤±è´¥ï¼‰ï¼Œä½†ä¸ä¼šæ¸…ç©º")
                except Exception as e:
                    log.warning(f"è¯»å–ç‰ˆæœ¬æ–‡ä»¶å¤±è´¥: {str(e)}ï¼Œä½†ä¸ä¼šæ¸…ç©º")
            else:
                log.info("ç‰ˆæœ¬æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä»é›¶å¼€å§‹åˆå§‹åŒ–")
            return versions
        
        def save_version_file(versions):
            version_path = Path("version.txt")
            with open(version_path, "w") as f:
                json.dump(versions, f, indent=2)
            log.info("ç‰ˆæœ¬æ–‡ä»¶å·²ä¿å­˜")
        
        def parse_cookies(cookie_str):
            cookies = {}
            for item in cookie_str.split(';'):
                item = item.strip()
                if not item:
                    continue
                if '=' in item:
                    key, value = item.split('=', 1)
                    cookies[key.strip()] = value.strip()
                else:
                    cookies[item] = None
            return cookies
        
        def get_safe_cookie_log(cookies):
            """å®‰å…¨è®°å½•Cookiesï¼ˆéšè—æ•æ„Ÿä¿¡æ¯ï¼‰"""
            safe_cookies = []
            sensitive_keys = ['__sdid', 'isg', 'tfstk', 'cookie', 'token', 'key', 'secret']
            
            for key, value in cookies.items():
                if any(sk in key.lower() for sk in sensitive_keys):
                    safe_cookies.append(f"{key}=***")
                else:
                    safe_cookies.append(f"{key}={value}")
            
            return ', '.join(safe_cookies)
        
        def decrypt_download_url(encrypted_url, file_key):
            """è§£å¯†å¤¸å…‹ç½‘ç›˜ä¸‹è½½URL"""
            try:
                # ç”ŸæˆAESå¯†é’¥
                aes_key = hashlib.md5(file_key.encode()).hexdigest().encode()
                iv = b"ef0e50a8a48afdac"
                
                # è§£ç base64
                encrypted_data = base64.b64decode(encrypted_url)
                
                # åˆ›å»ºè§£å¯†å™¨
                cipher = AES.new(aes_key, AES.MODE_CBC, iv)
                decrypted = cipher.decrypt(encrypted_data)
                
                # ç§»é™¤PKCS7å¡«å……
                pad = decrypted[-1]
                if 1 <= pad <= 16:
                    decrypted = decrypted[:-pad]
                
                return decrypted.decode('utf-8')
            except Exception as e:
                log.error(f"ä¸‹è½½URLè§£å¯†å¤±è´¥: {str(e)}")
                return None
        
        def get_all_share_files(share_url, cookies):
            """è·å–åˆ†äº«é“¾æ¥ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆå¸¦è¯¦ç»†æ—¥å¿—ï¼‰"""
            log.info(f"â³ å¼€å§‹è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨: {share_url}")
            
            # æå–åˆ†äº«ID
            share_id = share_url.split("/s/")[-1]
            if not share_id or len(share_id) != 32:
                log.error(f"âŒ æ— æ•ˆçš„åˆ†äº«URLæ ¼å¼ï¼Œæ— æ³•æå–share_id: {share_url}")
                return None
            
            log.info(f"åˆ†äº«ID: {share_id}")
            
            api_url = "https://drive-pc.quark.cn/1/clouddrive/share/sharepage/detail"
            
            headers = {
                "Referer": share_url,
                "Content-Type": "application/json",
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
            }
            
            # å®‰å…¨è®°å½•Cookies
            log.info(f"ä½¿ç”¨Cookies: {get_safe_cookie_log(cookies)}")
            
            all_files = []
            page = 1
            has_more = True
            error_occurred = False
            
            while has_more and not error_occurred:
                payload = {
                    "share_id": share_id,
                    "pdir_fid": "0",  # ä»æ ¹ç›®å½•å¼€å§‹
                    "page": page,
                    "per_page": 100,
                    "file_type": 0  # æ‰€æœ‰ç±»å‹
                }
                
                log.info(f"ğŸ“„ è¯·æ±‚ç¬¬ {page} é¡µï¼Œæ¯é¡µ {payload['per_page']} ä¸ªæ–‡ä»¶")
                log.debug(f"è¯·æ±‚è´Ÿè½½: {json.dumps(payload, ensure_ascii=False)}")
                
                try:
                    start_time = time.time()
                    response = requests.post(
                        api_url, 
                        json=payload, 
                        headers=headers, 
                        cookies=cookies,
                        timeout=30
                    )
                    
                    latency = time.time() - start_time
                    log.debug(f"HTTP çŠ¶æ€ç : {response.status_code} (å“åº”æ—¶é—´: {latency:.2f}s)")
                    
                    if response.status_code != 200:
                        log.error(f"âŒ APIè¯·æ±‚å¤±è´¥: HTTP {response.status_code}")
                        log.debug(f"å“åº”å¤´: {response.headers}")
                        log.debug(f"å“åº”æ–‡æœ¬: {response.text[:500]}...")
                        error_occurred = True
                        break
                    
                    try:
                        data = response.json()
                    except json.JSONDecodeError:
                        log.error(f"âŒ JSONè§£æå¤±è´¥: {response.text[:200]}")
                        error_occurred = True
                        break
                    
                    # æ£€æŸ¥APIé”™è¯¯ç 
                    api_status = data.get("status", {})
                    api_code = api_status.get("code")
                    
                    if api_code != 200 and api_code != None:
                        api_msg = api_status.get("message", "æœªçŸ¥é”™è¯¯")
                        log.error(f"âŒ APIè¿”å›é”™è¯¯: {api_code} - {api_msg}")
                        error_occurred = True
                        break
                    
                    # æ£€æŸ¥æ•°æ®ç»“æ„
                    if not isinstance(data.get("data"), dict):
                        log.error("âŒ æ— æ•ˆçš„APIå“åº”ç»“æ„: 'data'å­—æ®µç¼ºå¤±æˆ–éå­—å…¸ç±»å‹")
                        log.debug(f"å®Œæ•´å“åº”: {json.dumps(data, ensure_ascii=False)[:500]}...")
                        error_occurred = True
                        break
                    
                    # æå–æ–‡ä»¶åˆ—è¡¨
                    files_list = data.get("data", {}).get("list", [])
                    log.info(f"ğŸ“‚ ç¬¬ {page} é¡µè·å–åˆ° {len(files_list)} ä¸ªæ–‡ä»¶")
                    
                    if files_list:
                        # è®°å½•æ ·æœ¬æ–‡ä»¶
                        sample_files = [f"{f.get('file_name', 'æ— åæ–‡ä»¶')[:20]} ({f.get('size', 0)//1024}KB)" 
                                      for f in files_list[:3]]
                        if len(files_list) > 3:
                            sample_files.append(f"...ç­‰ {len(files_list)} ä¸ªæ–‡ä»¶")
                        
                        log.info(f"ğŸ“ æ–‡ä»¶æ ·æœ¬: {', '.join(sample_files)}")
                        
                        all_files.extend(files_list)
                    
                    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µé¢
                    has_more = data.get("data", {}).get("is_more", 0) == 1
                    page += 1
                    
                    # é¿å…é¢‘ç¹è¯·æ±‚
                    time.sleep(0.5)
                    
                    # å®‰å…¨é™åˆ¶: æœ€å¤š10é¡µ
                    if page > 10:
                        log.warning("âš ï¸ è¾¾åˆ°åˆ†é¡µé™åˆ¶(10é¡µ)ï¼Œåœæ­¢è·å–æ›´å¤šæ–‡ä»¶")
                        break
                    
                except requests.exceptions.Timeout:
                    log.error("âŒ› APIè¯·æ±‚è¶…æ—¶")
                    error_occurred = True
                    break
                except requests.exceptions.RequestException as re:
                    log.error(f"ğŸŒ ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {str(re)}")
                    error_occurred = True
                    break
                except Exception as e:
                    log.error(f"âŒ å¤„ç†åˆ†é¡µè¯·æ±‚æ—¶å‡ºé”™: {str(e)}")
                    error_occurred = True
                    break
            
            if error_occurred:
                log.error("âŒ æ–‡ä»¶åˆ—è¡¨è·å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯")
                return None
            
            if not all_files:
                log.warning("âš ï¸ è·å–åˆ°çš„æ–‡ä»¶åˆ—è¡¨ä¸ºç©º")
            else:
                log.info(f"âœ… æ€»å…±è·å–åˆ° {len(all_files)} ä¸ªæ–‡ä»¶")
                
            return all_files
        
        def find_files_by_template(files, templates, category):
            """é€šè¿‡ç²¾ç¡®è·¯å¾„æ¨¡æ¿æŸ¥æ‰¾æ–‡ä»¶"""
            found_files = {}
            
            if not files:
                log.warning(f"âš ï¸ {category}: æœªæä¾›æ–‡ä»¶åˆ—è¡¨")
                return found_files
            
            for file in files:
                if not file.get("file_name") or not file.get("path"):
                    log.debug("è·³è¿‡æ— æ–‡ä»¶åæˆ–è·¯å¾„çš„æ–‡ä»¶")
                    continue
                
                path = file.get("path", "") + "/" + file["file_name"]
                
                # å°è¯•åŒ¹é…æ¨¡æ¿
                for file_type, template in templates.items():
                    # ç”Ÿæˆæ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
                    pattern = re.escape(template)
                    pattern = pattern.replace(r"\{version\}", r"([\d.]+)")
                    pattern = pattern.replace(r"\{version_num\}", r"([\d.]+)")
                    pattern = r"^" + pattern + r"$"
                    
                    # åŒ¹é…è·¯å¾„
                    match = re.match(pattern, path)
                    if match:
                        version = match.group(1)
                        version_num = match.group(2)
                        
                        log.debug(f"âœ… åŒ¹é…æ¨¡æ¿ '{template}': æ–‡ä»¶ '{file['file_name']}'")
                        
                        if not version_num.replace(".", "").isdigit():
                            log.warning(f"âš ï¸ æ— æ•ˆç‰ˆæœ¬å·: {version_num} (æ–‡ä»¶: {file['file_name']})")
                            continue
                        
                        # æ›´æ–°æ–‡ä»¶è®°å½•
                        if file_type not in found_files or version_num > found_files[file_type]["version_num"]:
                            found_files[file_type] = {
                                "fid": file["fid"],
                                "key": file["hash_name"],
                                "version": version,
                                "version_num": version_num,
                                "path": path,
                                "size": file.get("size", 0),
                                "timestamp": file.get("updated_at", 0),
                                "file_name": file["file_name"]
                            }
                        break
            
            if not found_files:
                log.warning(f"âš ï¸ {category}: æœªæ‰¾åˆ°åŒ¹é…æ¨¡æ¿çš„æ–‡ä»¶")
            
            return found_files
        
        def should_update(versions, file_type, new_version, new_date):
            """åˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°æ­¤æ–‡ä»¶"""
            # æ–‡ä»¶ç±»å‹åœ¨ç‰ˆæœ¬æ–‡ä»¶ä¸­çš„é”®å
            key = RENAME_MAP.get(file_type)
            if not key:
                log.error(f"âŒ æ— æ•ˆçš„æ–‡ä»¶ç±»å‹æ ‡è¯†: {file_type}")
                return False
            
            # å¦‚æœç‰ˆæœ¬æ–‡ä»¶ä¸­ä¸å­˜åœ¨è®°å½•ï¼Œéœ€è¦æ›´æ–°
            if key not in versions:
                log.info(f"ğŸ“‹ æ–°æ–‡ä»¶: {key} (v{new_version})")
                return True
            
            current_val = versions[key]
            if ',' not in current_val:
                log.warning(f"ğŸ“‹ ç‰ˆæœ¬æ ¼å¼é”™è¯¯: {current_val}ï¼Œå¼ºåˆ¶æ›´æ–° {key}")
                return True
            
            # è§£æå½“å‰è®°å½•çš„ç‰ˆæœ¬å’Œæ—¥æœŸ
            try:
                current_ver, current_date = current_val.split(',', 1)
            except ValueError:
                log.warning(f"ğŸ“‹ ç‰ˆæœ¬æ ¼å¼è§£æå¤±è´¥: {current_val}ï¼Œå¼ºåˆ¶æ›´æ–° {key}")
                return True
            
            log.debug(f"ğŸ“‹ {key}: å½“å‰ç‰ˆæœ¬ = {current_ver}, å½“å‰æ—¥æœŸ = {current_date}")
            log.debug(f"ğŸ“‹ {key}: æ–°çš„ç‰ˆæœ¬ = {new_version}, æ–°çš„æ—¥æœŸ = {new_date}")
            
            # ç‰ˆæœ¬å·æ¯”è¾ƒ
            def version_tuple(v):
                return tuple(map(int, re.findall(r'\d+', v)))
            
            try:
                new_ver_tuple = version_tuple(new_version)
                current_ver_tuple = version_tuple(current_ver)
                
                # æ–°ç‰ˆæœ¬å·æ›´é«˜
                if new_ver_tuple > current_ver_tuple:
                    log.info(f"ğŸ†• æ–°ç‰ˆæœ¬: {key} ({current_ver} â†’ {new_version})")
                    return True
                
                # ç‰ˆæœ¬ç›¸åŒä½†æ—¥æœŸæ›´æ–°
                if new_ver_tuple == current_ver_tuple and new_date > current_date:
                    log.info(f"ğŸ†• ç›¸åŒç‰ˆæœ¬ä½†æ–°æ„å»º: {key} (ç‰ˆæœ¬ {new_version}, æ–°æ—¥æœŸ {new_date})")
                    return True
                
                log.debug(f"ğŸ“‹ {key}: æ— éœ€æ›´æ–° (ç‰ˆæœ¬ç›¸åŒ {current_ver})")
                return False
            except Exception as e:
                log.warning(f"ğŸ“‹ ç‰ˆæœ¬å·æ¯”è¾ƒå‡ºé”™: {str(e)}")
                # å¦‚æœæ— æ³•è§£æç‰ˆæœ¬å·ï¼ŒæŒ‰å­—ç¬¦ä¸²æ¯”è¾ƒ
                is_new = (new_version > current_ver) or (new_version == current_ver and new_date > current_date)
                if is_new:
                    log.info(f"ğŸ†• æ–°ç‰ˆæœ¬: {key} (å­—ç¬¦ä¸²æ¯”è¾ƒ: {current_ver} â†’ {new_version})")
                return is_new
        
        def download_file(cookies, file_info, save_path):
            """ä¸‹è½½å•ä¸ªæ–‡ä»¶"""
            fid = file_info["fid"]
            file_name = file_info["file_name"]
            file_key = file_info["key"]
            file_size = file_info.get("size", 0)
            
            # è·å–ä¸‹è½½é“¾æ¥
            api_url = f"https://drive-pc.quark.cn/1/clouddrive/file/download?fid={fid}"
            headers = {
                "Referer": "https://pan.quark.cn/",
                "Origin": "https://pan.quark.cn"
            }
            
            log.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {file_name} ({file_size//1024} KB)")
            log.debug(f"ä¸‹è½½æ–‡ä»¶ID: {fid}")
            
            try:
                response = requests.get(
                    api_url, 
                    cookies=cookies, 
                    headers=headers, 
                    allow_redirects=False,
                    timeout=20
                )
                
                if response.status_code == 302:
                    encrypted_url = response.headers.get("Location", "")
                elif response.json().get("data"):
                    encrypted_url = response.json().get("data")
                else:
                    log.error(f"âŒ æ— æ³•è·å–ä¸‹è½½URL")
                    return False
                
                if not encrypted_url:
                    log.error(f"âŒ æœªæ‰¾åˆ°ä¸‹è½½URL")
                    return False
                
                # è§£å¯†ä¸‹è½½URL
                download_url = decrypt_download_url(encrypted_url, file_key)
                if not download_url:
                    log.error(f"âŒ ä¸‹è½½URLè§£å¯†å¤±è´¥")
                    return False
                
                log.debug(f"ä¸‹è½½URLè·å–æˆåŠŸ")
                
                # åˆ›å»ºä¿å­˜ç›®å½•
                save_dir = os.path.dirname(save_path)
                if not os.path.exists(save_dir):
                    os.makedirs(save_dir)
                
                # ä¸‹è½½æ–‡ä»¶
                start_time = time.time()
                with requests.get(download_url, stream=True, timeout=60) as r:
                    r.raise_for_status()
                    
                    # è·å–å®é™…æ–‡ä»¶å¤§å°
                    content_length = int(r.headers.get('content-length', 0))
                    file_size = file_size or content_length
                    
                    log.info(f"æ–‡ä»¶å¤§å°: {file_size/(1024*1024):.2f} MB")
                    
                    with open(save_path, 'wb') as f:
                        downloaded = 0
                        last_log = time.time()
                        
                        for chunk in r.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                downloaded += len(chunk)
                                
                                # æ¯10%æˆ–æ¯ç§’æ‰“å°è¿›åº¦
                                now = time.time()
                                if now - last_log > 2 or downloaded == file_size:
                                    percent = downloaded / file_size * 100
                                    speed = downloaded / (now - start_time) / 1024  # KB/s
                                    log.info(f"ğŸ“Š ä¸‹è½½ä¸­... {percent:.1f}% ({speed:.1f} KB/s)")
                                    last_log = now
                
                # éªŒè¯æ–‡ä»¶å¤§å°
                downloaded_size = os.path.getsize(save_path)
                if downloaded_size != file_size:
                    log.error(f"âŒ æ–‡ä»¶å¤§å°ä¸åŒ¹é…: {downloaded_size} vs {file_size}")
                    os.remove(save_path)
                    return False
                
                elapsed = time.time() - start_time
                speed = downloaded_size / (elapsed * 1024)  # KB/s
                log.info(f"âœ… ä¸‹è½½å®Œæˆ! è€—æ—¶: {elapsed:.1f}s, å¹³å‡é€Ÿåº¦: {speed:.1f} KB/s")
                return True
                
            except requests.exceptions.RequestException as e:
                log.error(f"ğŸŒ ä¸‹è½½è¯·æ±‚å¤±è´¥: {str(e)}")
                return False
            except Exception as e:
                log.error(f"âŒ ä¸‹è½½è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                return False
        
        def main():
            log.info("=" * 70)
            log.info("ğŸš€ å¯åŠ¨å¤¸å…‹ç½‘ç›˜APKåŒæ­¥å·¥ä½œæµ")
            log.info("=" * 70)
            
            # è®°å½•ç¯å¢ƒä¿¡æ¯
            log.info(f"å·¥ä½œç›®å½•: {os.getcwd()}")
            log.info(f"Pythonç‰ˆæœ¬: {sys.version}")
            log.info(f"æ“ä½œç³»ç»Ÿ: {os.name}")
            
            # æ£€æŸ¥å¿…è¦ç¯å¢ƒå˜é‡
            if not os.environ.get("QUARK_CK"):
                log.critical("âŒ ç¼ºå°‘QUARK_CKç¯å¢ƒå˜é‡")
                return 1
                
            if not os.environ.get("GITHUB_TOKEN"):
                log.warning("âš ï¸ GITHUB_TOKENæœªæä¾›ï¼ŒæŸäº›Gitæ“ä½œå¯èƒ½å—é™")
                
            # è®¾ç½®Git
            if not setup_git():
                log.critical("âŒ Gitè®¾ç½®å¤±è´¥ï¼Œæ— æ³•ç»§ç»­")
                return 2
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            log.info(f"åˆ›å»ºä¸´æ—¶ç›®å½•: {WORK_DIR}")
            os.makedirs(WORK_DIR, exist_ok=True)
            os.makedirs(APK_DIR, exist_ok=True)
            
            # å®‰å…¨åŠ è½½ç‰ˆæœ¬æ–‡ä»¶
            current_versions = load_version_file()
            
            # è§£æCookies
            log.info("ğŸ” è§£æCookies...")
            quark_ck = os.environ["QUARK_CK"]
            if not quark_ck:
                log.error("âŒ QUARK_CKä¸ºç©º")
                return 3
                
            cookies = parse_cookies(quark_ck)
            
            # è·å–æ‰€æœ‰åˆ†äº«æ–‡ä»¶
            share_url = os.environ.get("SHARE_URL", "https://pan.quark.cn/s/6fead79bddaf")
            log.info(f"ğŸ” åˆ†äº«é“¾æ¥: {share_url}")
            
            # é‡è¯•æœºåˆ¶è·å–æ–‡ä»¶åˆ—è¡¨
            max_attempts = 3
            files = None
            for attempt in range(1, max_attempts + 1):
                log.info(f"ğŸ” å°è¯•è·å–åˆ†äº«æ–‡ä»¶åˆ—è¡¨ (å°è¯• {attempt}/{max_attempts})")
                files = get_all_share_files(share_url, cookies)
                
                if files is not None:  # æ³¨æ„: Noneè¡¨ç¤ºé”™è¯¯ï¼Œ[]è¡¨ç¤ºç©ºåˆ—è¡¨
                    if files:
                        log.info(f"âœ… æˆåŠŸè·å–æ–‡ä»¶åˆ—è¡¨: {len(files)}ä¸ªæ–‡ä»¶")
                        break
                    else:
                        log.warning("âš ï¸ æ–‡ä»¶åˆ—è¡¨ä¸ºç©º")
                else:
                    log.warning("âš ï¸ æ–‡ä»¶åˆ—è¡¨è·å–å¤±è´¥")
                
                if attempt < max_attempts:
                    wait_time = 10 * attempt
                    log.info(f"â³ ç­‰å¾…{wait_time}ç§’åé‡è¯•...")
                    time.sleep(wait_time)
            
            # æ£€æŸ¥ç»“æœ
            if not files:
                log.critical("âŒ æ— æ³•è·å–æœ‰æ•ˆçš„æ–‡ä»¶åˆ—è¡¨ï¼Œç»ˆæ­¢åŒæ­¥")
                return 3
            
            # æŸ¥æ‰¾æ ‡å‡†ç‰ˆæ–‡ä»¶
            log.info("=" * 70)
            log.info("ğŸ” æœç´¢æ ‡å‡†ç‰ˆæ–‡ä»¶")
            std_files = find_files_by_template(files, STD_PATH_TEMPLATES, "æ ‡å‡†ç‰ˆ")
            
            # æŸ¥æ‰¾ä¸“ä¸šç‰ˆæ–‡ä»¶
            log.info("=" * 70)
            log.info("ğŸ” æœç´¢ä¸“ä¸šç‰ˆæ–‡ä»¶")
            pro_files = find_files_by_template(files, PRO_PATH_TEMPLATES, "ä¸“ä¸šç‰ˆ")
            
            # å¤„ç†æ›´æ–°
            log.info("=" * 70)
            log.info("ğŸ”„ å¼€å§‹å¤„ç†æ›´æ–°")
            needs_update = False
            update_log = []
            
            # å¤„ç†æ ‡å‡†ç‰ˆ
            if std_files:
                sample_file = next(iter(std_files.values()))
                
                # è·å–æ—¥æœŸ
                dt = datetime.fromtimestamp(sample_file["timestamp"]/1000)
                dt_beijing = dt.astimezone(TZ_BEIJING)
                date_str = dt_beijing.strftime("%Y-%m-%d")
                
                log.info(f"ğŸ¯ æ ‡å‡†ç‰ˆç‰ˆæœ¬: {sample_file['version']}, å‘å¸ƒ: {date_str}")
                
                for file_type, file_info in std_files.items():
                    key_name = f"std_{file_type}"
                    
                    if should_update(current_versions, key_name, file_info["version"], date_str):
                        temp_path = os.path.join(WORK_DIR, file_info["file_name"])
                        if download_file(cookies, file_info, temp_path):
                            # åˆ›å»ºç›®æ ‡è·¯å¾„
                            dest_name = RENAME_MAP[key_name]
                            dest_path = os.path.join(APK_DIR, dest_name)
                            
                            # åˆ é™¤æ—§æ–‡ä»¶
                            if os.path.exists(dest_path):
                                os.remove(dest_path)
                            
                            # ç§»åŠ¨æ–‡ä»¶
                            os.rename(temp_path, dest_path)
                            log.info(f"ğŸ†• æ–‡ä»¶å·²ä¿å­˜ä¸º: {dest_name}")
                            
                            # æ›´æ–°ç‰ˆæœ¬è®°å½•
                            current_versions[RENAME_MAP[key_name]] = f"{file_info['version']},{date_str}"
                            update_log.append(f"{dest_name} (v{file_info['version']})")
                            needs_update = True
                        else:
                            log.error(f"âŒ ä¸‹è½½å¤±è´¥: {RENAME_MAP[key_name]}")
                    else:
                        log.debug(f"â†ªï¸ è·³è¿‡: {RENAME_MAP[key_name]} (æ— éœ€æ›´æ–°)")
            else:
                log.warning("âš ï¸ è·³è¿‡æ ‡å‡†ç‰ˆå¤„ç†")
                
            # å¤„ç†ä¸“ä¸šç‰ˆ
            if pro_files:
                sample_file = next(iter(pro_files.values()))
                
                # è·å–æ—¥æœŸ
                dt = datetime.fromtimestamp(sample_file["timestamp"]/1000)
                dt_beijing = dt.astimezone(TZ_BEIJING)
                date_str = dt_beijing.strftime("%Y-%m-%d")
                
                log.info(f"ğŸ¯ ä¸“ä¸šç‰ˆç‰ˆæœ¬: {sample_file['version_num']}, å‘å¸ƒ: {date_str}")
                
                for file_type, file_info in pro_files.items():
                    key_name = f"pro_{file_type}"
                    
                    if should_update(current_versions, key_name, file_info["version_num"], date_str):
                        temp_path = os.path.join(WORK_DIR, file_info["file_name"])
                        if download_file(cookies, file_info, temp_path):
                            # åˆ›å»ºç›®æ ‡è·¯å¾„
                            dest_name = RENAME_MAP[key_name]
                            dest_path = os.path.join(APK_DIR, dest_name)
                            
                            # åˆ é™¤æ—§æ–‡ä»¶
                            if os.path.exists(dest_path):
                                os.remove(dest_path)
                            
                            # ç§»åŠ¨æ–‡ä»¶
                            os.rename(temp_path, dest_path)
                            log.info(f"ğŸ†• æ–‡ä»¶å·²ä¿å­˜ä¸º: {dest_name}")
                            
                            # æ›´æ–°ç‰ˆæœ¬è®°å½•
                            current_versions[RENAME_MAP[key_name]] = f"{file_info['version_num']},{date_str}"
                            update_log.append(f"{dest_name} (v{file_info['version_num']})")
                            needs_update = True
                        else:
                            log.error(f"âŒ ä¸‹è½½å¤±è´¥: {RENAME_MAP[key_name]}")
                    else:
                        log.debug(f"â†ªï¸ è·³è¿‡: {RENAME_MAP[key_name]} (æ— éœ€æ›´æ–°)")
            else:
                log.warning("âš ï¸ è·³è¿‡ä¸“ä¸šç‰ˆå¤„ç†")
            
            # éªŒè¯ç»“æœ
            all_files_ok = True
            for key, file_name in RENAME_MAP.items():
                apk_path = os.path.join(APK_DIR, file_name)
                if not os.path.exists(apk_path):
                    log.error(f"âŒ å…³é”®æ–‡ä»¶ç¼ºå¤±: {file_name}")
                    all_files_ok = False
            
            # å¦‚æœæœ‰æ›´æ–°æˆ–æ–‡ä»¶ç¼ºå¤±
            if needs_update or not all_files_ok:
                if needs_update:
                    log.info("ğŸ’¾ ä¿å­˜ç‰ˆæœ¬æ–‡ä»¶")
                    save_version_file(current_versions)
                    
                    if update_log:
                        commit_msg = "æ›´æ–°APK: " + ", ".join(update_log)
                    else:
                        commit_msg = "å¼ºåˆ¶æ›´æ–°ç¼ºå¤±æ–‡ä»¶"
                    
                    if commit_and_push(commit_msg):
                        log.info("âœ… åŒæ­¥æˆåŠŸ!")
                        return 0
                    else:
                        log.error("âŒ æäº¤å¤±è´¥")
                        return 4
                else:
                    log.error("âŒ éœ€è¦æ›´æ–°ä½†æ— æ³•å®Œæˆæ“ä½œ")
                    return 5
            else:
                log.info("âœ… æ‰€æœ‰æ–‡ä»¶å‡ä¸ºæœ€æ–°ç‰ˆæœ¬")
                return 0
        
        if __name__ == "__main__":
            try:
                exit_code = main()
                log.info("=" * 70)
                log.info(f"ğŸ å·¥ä½œæµç»“æŸ (ä»£ç : {exit_code})")
                log.info("=" * 70)
                sys.exit(exit_code)
            except Exception as e:
                import traceback
                log.error(f"âŒ æœªæ•è·çš„å¼‚å¸¸: {str(e)}")
                log.error(traceback.format_exc())
                sys.exit(99)
        EOF

    - name: Archive log file
      if: always()
      run: |
        echo "Archive sync log"
        timestamp=$(date +%Y%m%d_%H%M%S)
        cp quark_sync.log "quark_sync_${timestamp}.log"
        gzip "quark_sync_${timestamp}.log"
        
    - name: Upload logs
      if: always()
      uses: actions/upload-artifact@v4  # æ›´æ–°åˆ° v4
      with:
        name: sync-logs
        path: quark_sync_*.log.gz

    - name: Release Repository Lock ğŸ”“
      if: always()
      uses: softprops/turnstyle@v1
      with:
        continue-on-error: true
        action: unlock
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    - name: Notify on failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          const message = `ğŸš¨ Quarkç½‘ç›˜APKåŒæ­¥å¤±è´¥ï¼å·¥ä½œæµè¿è¡Œ: [${{ github.workflow }} #${{ github.run_number }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`;
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: message
          })

  cleanup:
    runs-on: ubuntu-latest
    needs: sync
    if: always()
    steps:
      - name: Clean up workspace
        run: |
          # åˆ é™¤ä¸´æ—¶å·¥ä½œç›®å½•
          rm -rf temp_apks
          
          # æ¸…é™¤æœªè·Ÿè¸ªçš„æ–‡ä»¶
          git clean -f -d
          
          # ä¿ç•™æ—¥å¿—æ–‡ä»¶
          rm -f quark_sync.log
